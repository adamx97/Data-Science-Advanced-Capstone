{
    "cells": [
        {
            "metadata": {
                "collapsed": true
            },
            "cell_type": "markdown",
            "source": "### Deep learning with Word2Vec Models\nWe will combine the 1D Convolutional model with Word2Vec embeddings.\n"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "!pip install --upgrade numpy\n!pip install --upgrade pandas\n#!pip install pyspark==2.4.5\n!pip install -U scikit-learn\n!pip install gensim",
            "execution_count": 1,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Collecting numpy\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/97/af8a92864a04bfa48f1b5c9b1f8bf2ccb2847f24530026f26dd223de4ca0/numpy-1.19.2-cp36-cp36m-manylinux2010_x86_64.whl (14.5MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14.5MB 7.7MB/s eta 0:00:01\n\u001b[31mERROR: tensorflow 1.13.1 requires tensorboard<1.14.0,>=1.13.0, which is not installed.\u001b[0m\n\u001b[31mERROR: autoai-libs 1.10.5 has requirement pandas>=0.24.2, but you'll have pandas 0.24.1 which is incompatible.\u001b[0m\n\u001b[?25hInstalling collected packages: numpy\n  Found existing installation: numpy 1.15.4\n    Uninstalling numpy-1.15.4:\n      Successfully uninstalled numpy-1.15.4\nSuccessfully installed numpy-1.19.2\nCollecting pandas\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/11/e1f53db0614f2721027aab297c8afd2eaf58d33d566441a97ea454541c5e/pandas-1.1.2-cp36-cp36m-manylinux1_x86_64.whl (10.5MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10.5MB 8.1MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied, skipping upgrade: pytz>=2017.2 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pandas) (2018.9)\nRequirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pandas) (2.7.5)\nRequirement already satisfied, skipping upgrade: numpy>=1.15.4 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pandas) (1.19.2)\nRequirement already satisfied, skipping upgrade: six>=1.5 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from python-dateutil>=2.7.3->pandas) (1.12.0)\n\u001b[31mERROR: ibm-watson-machine-learning 1.0.10 has requirement pandas<=0.25.3, but you'll have pandas 1.1.2 which is incompatible.\u001b[0m\nInstalling collected packages: pandas\n  Found existing installation: pandas 0.24.1\n    Uninstalling pandas-0.24.1:\n      Successfully uninstalled pandas-0.24.1\nSuccessfully installed pandas-1.1.2\nCollecting scikit-learn\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/a1/273def87037a7fb010512bbc5901c31cfddfca8080bc63b42b26e3cc55b3/scikit_learn-0.23.2-cp36-cp36m-manylinux1_x86_64.whl (6.8MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 6.8MB 7.6MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.13.3 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from scikit-learn) (1.19.2)\nCollecting joblib>=0.11 (from scikit-learn)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/dd/0e015051b4a27ec5a58b02ab774059f3289a94b0906f880a3f9507e74f38/joblib-0.16.0-py3-none-any.whl (300kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 307kB 30.4MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied, skipping upgrade: scipy>=0.19.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from scikit-learn) (1.2.0)\nCollecting threadpoolctl>=2.0.0 (from scikit-learn)\n  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n\u001b[31mERROR: autoai-libs 1.10.5 has requirement scikit-learn==0.20.3, but you'll have scikit-learn 0.23.2 which is incompatible.\u001b[0m\nInstalling collected packages: joblib, threadpoolctl, scikit-learn\n  Found existing installation: scikit-learn 0.20.3\n    Uninstalling scikit-learn-0.20.3:\n      Successfully uninstalled scikit-learn-0.20.3\nSuccessfully installed joblib-0.16.0 scikit-learn-0.23.2 threadpoolctl-2.1.0\nCollecting gensim\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/e0/fa6326251692056dc880a64eb22117e03269906ba55a6864864d24ec8b4e/gensim-3.8.3-cp36-cp36m-manylinux1_x86_64.whl (24.2MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24.2MB 6.1MB/s eta 0:00:01    |\u2588\u2588\u2588                             | 2.2MB 6.1MB/s eta 0:00:04\n\u001b[?25hRequirement already satisfied: six>=1.5.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from gensim) (1.12.0)\nRequirement already satisfied: scipy>=0.18.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from gensim) (1.2.0)\nCollecting smart-open>=1.8.1 (from gensim)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/6f/788e657fb513deebadfbb38b346d4878b2fded0f72fe7d937b1646137f46/smart_open-2.1.1.tar.gz (111kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 112kB 31.4MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from gensim) (1.19.2)\nRequirement already satisfied: requests in /opt/conda/envs/Python36/lib/python3.6/site-packages (from smart-open>=1.8.1->gensim) (2.21.0)\nRequirement already satisfied: boto in /opt/conda/envs/Python36/lib/python3.6/site-packages (from smart-open>=1.8.1->gensim) (2.49.0)\nRequirement already satisfied: boto3 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from smart-open>=1.8.1->gensim) (1.9.82)\nRequirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim) (2.8)\nRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim) (2020.6.20)\nRequirement already satisfied: urllib3<1.25,>=1.21.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim) (1.24.1)\nRequirement already satisfied: botocore<1.13.0,>=1.12.82 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from boto3->smart-open>=1.8.1->gensim) (1.12.82)\nRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.9.3)\nRequirement already satisfied: s3transfer<0.2.0,>=0.1.10 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.1.13)\nRequirement already satisfied: docutils>=0.10 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.82->boto3->smart-open>=1.8.1->gensim) (0.14)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.82->boto3->smart-open>=1.8.1->gensim) (2.7.5)\nBuilding wheels for collected packages: smart-open\n  Building wheel for smart-open (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /home/dsxuser/.cache/pip/wheels/17/49/ea/74939572d8d071ff3c63a98e3e8dadef1117cc93c33efaa504\nSuccessfully built smart-open\nInstalling collected packages: smart-open, gensim\nSuccessfully installed gensim-3.8.3 smart-open-2.1.1\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "%matplotlib inline\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom pprint import pprint\nfrom time import time\nimport logging\nimport numpy as np\nimport pandas as pd\nimport string\nimport re\nfrom datetime import datetime\nfrom packaging import version\n\nfrom ibm_botocore.client import Config\nimport ibm_boto3\n\nfrom sklearn.model_selection import train_test_split\n#pd.show_versions()",
            "execution_count": 2,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#Get our data from IBM Cloud\n\n# @hidden_cell\n# The following code contains the credentials for a file in your IBM Cloud Object Storage.\n# You might want to remove those credentials before you share your notebook.\ncredentials_news = {\n    'IAM_SERVICE_ID': 'iam-ServiceId-32e8ee67-397c-4ff1-b69b-543172331f43',\n    'IBM_API_KEY_ID': 'Rx4FR4JSAueCnnIsoevsgYgOsuh8LCXtbkFpFpC0EmVU',\n    #'ENDPOINT': 'https://s3-api.us-geo.objectstorage.service.networklayer.com',\n    'ENDPOINT':'https://s3-api.us-geo.objectstorage.softlayer.net',\n    'IBM_AUTH_ENDPOINT': 'https://iam.cloud.ibm.com/oidc/token',\n    'BUCKET': 'advanceddatasciencecapstone-donotdelete-pr-tqabpnbxebk8rm',\n    'FILE': 'dfTrueFalseNews.pkl'\n}\n\ndef download_file_cos(credentials,local_file_name,key):  \n    cos = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id=credentials['IBM_API_KEY_ID'],\n    ibm_service_instance_id=credentials['IAM_SERVICE_ID'],\n    ibm_auth_endpoint=credentials['IBM_AUTH_ENDPOINT'],\n    config=Config(signature_version='oauth'),\n    endpoint_url=credentials['ENDPOINT'])\n    try:\n        res=cos.download_file(Bucket=credentials['BUCKET'],Key=key,Filename=local_file_name)\n    except Exception as e:\n        print(Exception, e)\n    else:\n        print('File Downloaded')\n\ndef upload_file_cos(credentials,local_file_name,key):  \n    cos = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id=credentials['IBM_API_KEY_ID'],\n    ibm_service_instance_id=credentials['IAM_SERVICE_ID'],\n    ibm_auth_endpoint=credentials['IBM_AUTH_ENDPOINT'],\n    config=Config(signature_version='oauth'),\n    endpoint_url=credentials['ENDPOINT'])\n    try:\n        res=cos.upload_file(Filename=local_file_name, Bucket=credentials['BUCKET'],Key=key)\n    except Exception as e:\n        print(Exception, e)\n    else:\n        print(' File Uploaded')\n        \ndfNews = download_file_cos(credentials_news, \"dfTrueFalseNews.pkl\", \"dfTrueFalseNews.pkl\")\ndfTrueFalseNews_tokenized  = download_file_cos(credentials_news,'dfTrueFalseNews_tokenized.pkl','dfTrueFalseNews_tokenized.pkl')",
            "execution_count": 3,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "File Downloaded\nFile Downloaded\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "dfNewsTemp = pd.read_pickle('dfTrueFalseNews.pkl')\ndfTrueFalseNews_tokenized = pd.read_pickle('dfTrueFalseNews_tokenized.pkl')\n#dfNews['truthvalue'] = pd.Categorical(dfNews['truthvalue'])\n\nx = dfNewsTemp['text'].values\n\ny = dfNewsTemp['truthvalue'].values\n\nprint (dfNewsTemp.shape, dfNewsTemp.columns, '\\n', dfNewsTemp.dtypes, type(x), type(y))\n",
            "execution_count": 4,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "(1126, 3) Index(['text', 'source', 'truthvalue'], dtype='object') \n text          object\nsource        object\ntruthvalue    object\ndtype: object <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### Prepare the Text for Word2Vec\n1. Change all the text to lower case\n2. Split stories into sentences.\n3. Word Tokenization and removing non-alpha text."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from nltk.tokenize import word_tokenize\nfrom nltk.tokenize import sent_tokenize\nfrom nltk import pos_tag\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.stem.porter import *\nfrom nltk.corpus import wordnet as wn\nfrom collections import defaultdict\nimport nltk\nnltk.download('punkt')\nnltk.download('wordnet')\nnltk.download('averaged_perceptron_tagger')\nnltk.download('stopwords')\n\n# reproduce the same result every time the script is run.\nnp.random.seed(500)",
            "execution_count": 5,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "[nltk_data] Downloading package punkt to /home/dsxuser/nltk_data...\n[nltk_data]   Unzipping tokenizers/punkt.zip.\n[nltk_data] Downloading package wordnet to /home/dsxuser/nltk_data...\n[nltk_data]   Unzipping corpora/wordnet.zip.\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /home/dsxuser/nltk_data...\n[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n[nltk_data] Downloading package stopwords to\n[nltk_data]     /home/dsxuser/nltk_data...\n[nltk_data]   Unzipping corpora/stopwords.zip.\n",
                    "name": "stderr"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from gensim.models import Word2Vec\ndownload_file_cos(credentials_news,\"embedding_word2vec.model\",\"embedding_word2vec.model\")\nmodel = Word2Vec.load(\"embedding_word2vec.model\")\nmodel_vectors = model.wv\nwords = list(model.wv.vocab)\nprint('Vocabulary size: %d' % len(words))",
            "execution_count": 6,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "File Downloaded\nVocabulary size: 21671\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Split into Train_X, Train_Y, Test_X, Test_Y\nfrom sklearn import model_selection\nTrain_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split(dfNewsTemp['text'],dfNewsTemp['truthvalue'],test_size=0.1)",
            "execution_count": 8,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "type(Test_Y)",
            "execution_count": 22,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 22,
                    "data": {
                        "text/plain": "pandas.core.series.Series"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### Define a Vocabulary based on all the words in our stories\nSave it as vocab.txt\nbased on https://machinelearningmastery.com/develop-word-embedding-model-predicting-movie-review-sentiment/"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from string import punctuation\nfrom os import listdir\nfrom collections import Counter\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nwnl = WordNetLemmatizer()\nstop_words = set(stopwords.words('english'))\n\n\n# from: https://www.machinelearningplus.com/nlp/lemmatization-examples-python/\n# Lemmatize with POS Tag\nfrom nltk.corpus import wordnet\n\ndef get_wordnet_pos(word):\n    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n    tag = nltk.pos_tag([word])[0][1][0].upper()\n    tag_dict = {\"J\": wordnet.ADJ,\n                \"N\": wordnet.NOUN,\n                \"V\": wordnet.VERB,\n                \"R\": wordnet.ADV}\n\n    return tag_dict.get(tag, wordnet.NOUN)\n\n\n# turn a doc into clean tokens\ndef clean_doc(doc):\n    # split into tokens by white space\n    doc = doc.lower()\n    tokens = doc.split()\n    # remove punctuation from each token\n    table = str.maketrans('', '', punctuation)\n    tokens = [w.translate(table) for w in tokens]\n    # remove remaining tokens that are not alphabetic\n    tokens = [word for word in tokens if word.isalpha()]\n    # filter out stop words\n    #stop_words = set(stopwords.words('english'))\n    tokens = [w for w in tokens if not w in stop_words]\n    tokens = [wnl.lemmatize(w, get_wordnet_pos(w)) for w in tokens]\n    # filter out short tokens\n    tokens = [word for word in tokens if len(word) > 1]\n    return tokens\n\n# load doc and add to vocab\ndef add_doc_to_vocab(story, vocab):\n    # load doc\n    #doc = load_doc(filename)\n    # clean doc\n    tokens = clean_doc(story)\n    # update counts\n    vocab.update(tokens)\n\n# load all docs in a directory\ndef process_docs(x, vocab):\n    # walk through all files in the folder\n    for story in x:\n        # skip any reviews in the test set\n        # add doc to vocab\n        add_doc_to_vocab(story, vocab)\n\n# define vocab\nvocab = Counter()\n# add all docs to vocab\nprocess_docs(Train_X, vocab)\n#process_docs('txt_sentoken/pos', vocab, True)\n# print the size of the vocab\nprint(len(vocab))\n# print the top words in the vocab\nprint(vocab.most_common(50))\n\n\n",
            "execution_count": 8,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "17697\n[('say', 2013), ('get', 879), ('one', 873), ('make', 867), ('go', 856), ('new', 821), ('like', 792), ('time', 780), ('year', 756), ('would', 691), ('take', 634), ('also', 604), ('know', 581), ('show', 572), ('people', 565), ('come', 552), ('want', 517), ('first', 517), ('trump', 516), ('see', 478), ('told', 476), ('source', 476), ('star', 471), ('work', 464), ('think', 450), ('report', 450), ('back', 448), ('well', 439), ('two', 439), ('thing', 430), ('even', 425), ('life', 416), ('look', 399), ('could', 391), ('last', 380), ('give', 366), ('way', 357), ('day', 354), ('world', 348), ('love', 347), ('family', 345), ('friend', 343), ('use', 341), ('president', 335), ('accord', 327), ('state', 322), ('really', 321), ('child', 316), ('many', 301), ('may', 298)]\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#We can step through the vocabulary and remove all words that have a low occurrence, such as only being used once or twice\nmin_occurance = 2\ntokens = [k for k,c in vocab.items() if c >= min_occurance]\nprint(len(tokens), tokens[1:10])",
            "execution_count": 14,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "10312 ['claim', 'trump', 'touch', 'exclusive', 'interview', 'hollywood', 'inquirer', 'say', 'mr']\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def save_list(lines, filename):\n    # convert lines to a single blob of text\n    data = '\\n'.join(lines)\n    # open file\n    file = open(filename, 'w')\n    # write text\n    file.write(data)\n    # close file\n    file.close()\n \n# save tokens to a vocabulary file\nsave_list(tokens, 'vocab.txt')\nupload_file_cos(credentials_news,'vocab.txt','vocab.txt')",
            "execution_count": 13,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": " File Uploaded\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Use simple pruned vocabulary from above in our deep learning model."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from string import punctuation\nfrom os import listdir\nfrom numpy import array\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.layers import Conv1D\nfrom tensorflow.keras.layers import MaxPooling1D\nfrom tensorflow.data import Dataset",
            "execution_count": 12,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# based on https://machinelearningmastery.com/develop-word-embedding-model-predicting-movie-review-sentiment/\n\n\nwnl = WordNetLemmatizer()\nstop_words = set(stopwords.words('english'))\n\nfrom nltk.corpus import wordnet\n\ndef get_wordnet_pos(word):\n    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n    tag = nltk.pos_tag([word])[0][1][0].upper()\n    tag_dict = {\"J\": wordnet.ADJ,\n                \"N\": wordnet.NOUN,\n                \"V\": wordnet.VERB,\n                \"R\": wordnet.ADV}\n\n    return tag_dict.get(tag, wordnet.NOUN)\n\n# load doc into memory\ndef load_doc(filename):\n    # open the file as read only\n    file = open(filename, 'r')\n    # read all text\n    text = file.read()\n    # close the file\n    file.close()\n    return text\n\n# turn a doc into clean tokens\ndef clean_doc(doc, vocab):\n    # split into tokens by white space\n    tokens = doc.split()\n    # remove punctuation from each token\n    table = str.maketrans('', '', punctuation)\n    tokens = [w.translate(table) for w in tokens]\n    # remove remaining tokens that are not alphabetic\n    tokens = [word for word in tokens if word.isalpha()]\n    tokens = [wnl.lemmatize(w, get_wordnet_pos(w)) for w in tokens]\n    # filter out tokens not in vocab\n    tokens = [w for w in tokens if w in vocab]\n    \n    tokens = ' '.join(tokens)\n    return tokens\n\n# load all docs in a directory\ndef process_docs(x, vocab):\n    documents = list()\n    # walk through all files in the folder\n    #for filename in listdir(directory):\n    for doc in x:\n        # skip any reviews in the test set\n        #if is_trian and filename.startswith('cv9'):\n        #    continue\n        #if not is_train: # and not filename.startswith('cv9'):\n        #    continue\n        # create the full path of the file to open\n        #path = directory + '/' + filename\n        # load the doc\n        #doc = load_doc(path)\n        # clean doc\n        tokens = clean_doc(doc, vocab)\n        # add to list\n        documents.append(tokens)\n    return documents\n\n# load the vocabulary\ndownload_file_cos(credentials_news,'vocab.txt','vocab.txt')\nvocab_filename = 'vocab.txt'\nvocab = load_doc(vocab_filename)\nvocab = vocab.split()\nvocab = set(vocab)\n\n# load all training reviews\n#positive_docs = process_docs(Train_X, vocab)\n#negative_docs = process_docs('txt_sentoken/neg', vocab, True)\ntrain_docs = process_docs(Train_X, vocab)\n\n# create the tokenizer\ntokenizer = Tokenizer()\n# fit the tokenizer on the documents\ntokenizer.fit_on_texts(train_docs)\n\n# sequence encode\nencoded_docs = tokenizer.texts_to_sequences(train_docs)\n# pad sequences\nmax_length = max([len(s.split()) for s in train_docs])\nXtrain = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n# define training labels\nytrain = Train_Y #array([0 for _ in range(900)] + [1 for _ in range(900)])\n\n# load all test reviews\n#positive_docs = process_docs('txt_sentoken/pos', vocab, False)\n#negative_docs = process_docs('txt_sentoken/neg', vocab, False)\n\ntest_docs = process_docs(Test_X, vocab)#  negative_docs + positive_docs\n# sequence encode\nencoded_docs = tokenizer.texts_to_sequences(test_docs)\n# pad sequences\nXtest = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n# define test labels\nytest = Test_Y # array([0 for _ in range(100)] + [1 for _ in range(100)])\n\n# define vocabulary size (largest integer value)\nvocab_size = len(tokenizer.word_index) + 1\n\n# zip test data\n\n#validation_data = Dataset.zip((Xtest, ytest))\n\n# define model\nmodel = Sequential()\nmodel.add(Embedding(vocab_size, 100, input_length=max_length))\nmodel.add(Conv1D(filters=32, kernel_size=8, activation='relu'))\nmodel.add(MaxPooling1D(pool_size=2))\nmodel.add(Flatten())\nmodel.add(Dense(10, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nprint(model.summary())\n\n# compile network\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n# fit network\nhistory = model.fit(Xtrain, ytrain, epochs=9, validation_data=(Xtest, ytest))\n# evaluate\nloss, acc = model.evaluate(Xtest, ytest, verbose=0)\nprint('Test Accuracy: %f Loss: %f' % (acc*100, loss * 100 ))",
            "execution_count": 13,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "File Downloaded\nWARNING:tensorflow:From /opt/conda/envs/Python36/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_1 (Embedding)      (None, 6347, 100)         752000    \n_________________________________________________________________\nconv1d_1 (Conv1D)            (None, 6340, 32)          25632     \n_________________________________________________________________\nmax_pooling1d_1 (MaxPooling1 (None, 3170, 32)          0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 3170, 256)         8448      \n_________________________________________________________________\ndropout (Dropout)            (None, 3170, 256)         0         \n_________________________________________________________________\nflatten (Flatten)            (None, 811520)            0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 100)               81152100  \n_________________________________________________________________\ndense_3 (Dense)              (None, 1)                 101       \n=================================================================\nTotal params: 81,938,281\nTrainable params: 81,938,281\nNon-trainable params: 0\n_________________________________________________________________\nNone\nTrain on 1013 samples, validate on 113 samples\nWARNING:tensorflow:From /opt/conda/envs/Python36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\nEpoch 1/9\n1013/1013 [==============================] - 153s 151ms/sample - loss: 0.7261 - acc: 0.4719 - val_loss: 0.6923 - val_acc: 0.4248\nEpoch 2/9\n1013/1013 [==============================] - 150s 148ms/sample - loss: 0.6794 - acc: 0.5489 - val_loss: 0.6933 - val_acc: 0.4867\nEpoch 3/9\n1013/1013 [==============================] - 150s 148ms/sample - loss: 0.5635 - acc: 0.7275 - val_loss: 0.7849 - val_acc: 0.4956\nEpoch 4/9\n1013/1013 [==============================] - 149s 147ms/sample - loss: 0.1748 - acc: 0.9497 - val_loss: 1.3833 - val_acc: 0.4425\nEpoch 5/9\n1013/1013 [==============================] - 149s 147ms/sample - loss: 0.0397 - acc: 0.9891 - val_loss: 1.5423 - val_acc: 0.4513\nEpoch 6/9\n 608/1013 [=================>............] - ETA: 56s - loss: 0.0214 - acc: 0.9967 ",
                    "name": "stdout"
                },
                {
                    "output_type": "error",
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                        "\u001b[0;32m<ipython-input-13-b6cfc728ae22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;31m# fit network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;31m# evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    878\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m   def evaluate(self,\n",
                        "\u001b[0;32m/opt/conda/envs/Python36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python36/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
                        "\u001b[0;32m/opt/conda/envs/Python36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
                    ]
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "history_dict\nimport pickle\n\n\nfilename = \"deeplearningWithOurVocab.history\"\nwith open(filename, 'wb') as f:\n    pickle.dump(history_dict, f)\n    \n# with open(filename, 'rb') as f:\n#     data = pickle.load(f)",
            "execution_count": 26,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 26,
                    "data": {
                        "text/plain": "{'loss': [0.6936446398290689,\n  0.6590700409607732,\n  0.5260552331466901,\n  0.22124794996384925,\n  0.043527796489406315,\n  0.013775162661755191,\n  0.0061495141015890965,\n  0.00421735854026,\n  0.0032471866025230852],\n 'acc': [0.5202369,\n  0.6189536,\n  0.87956566,\n  0.9851925,\n  0.9970385,\n  0.99802566,\n  0.9990128,\n  0.9990128,\n  0.9990128],\n 'val_loss': [0.6915967991921754,\n  0.6837951240286363,\n  0.6828052491213368,\n  0.7544672737079384,\n  0.8891760807121749,\n  0.9134258300857206,\n  0.8836142341647528,\n  0.9235463363934407,\n  0.9559872667346381],\n 'val_acc': [0.45132744,\n  0.54867256,\n  0.54867256,\n  0.539823,\n  0.5132743,\n  0.53097343,\n  0.5663717,\n  0.57522124,\n  0.57522124]}"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#model.save('deeplearning_newsvocab.model')\n#upload_file_cos(credentials_news,'deeplearning_newsvocab.model', 'deeplearning_newsvocab.model')\n\n#results = model2.evaluate(tfds_test)\n\n#print(results)\nhistory_dict = history.history\nhistory_dict.keys()\n\nacc = history_dict['acc']\nval_acc = history_dict['val_acc']\nloss = history_dict['loss']\nval_loss = history_dict['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\n# \"bo\" is for \"blue dot\"\nplt.plot(epochs, loss, 'bo', label='Training loss')\n# b is for \"solid blue line\"\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n",
            "execution_count": 27,
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": "<Figure size 432x288 with 1 Axes>",
                        "image/png": "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\n"
                    },
                    "metadata": {
                        "needs_background": "light"
                    }
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "plt.clf()   # clear figure\n\nplt.plot(epochs, acc, 'ro', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.show()",
            "execution_count": 28,
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": "<Figure size 432x288 with 1 Axes>",
                        "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xt8VNW5//HPw0Ug3CV445Lgpd4oKMaAigpi+Yk3qniqiKdVqlRbvJ2eViq2WhVPq9ZjrR6PeGm1pFKOFpVW8YIoXqoSFFBAhSoiAhIQuSMEn98fa2eYDJNkwEz2JPm+X695zey91+x5ZibZz+y11l7L3B0RERGAJnEHICIiuUNJQUREEpQUREQkQUlBREQSlBRERCRBSUFERBKUFGQnZtbUzDaYWffaLBsnMzvQzGq9/7WZnWxmi5OWPzCz4zMpuxuv9YCZXbu7zxfJRLO4A5Bvzsw2JC3mAV8B26PlH7l7ya7sz923A21qu2xj4O4H18Z+zOxi4AJ3H5C074trY98i1VFSaADcPXFQjn6JXuzuL1RV3syauXt5XcQmUhP9PeYWVR81AmZ2s5n91cweNbP1wAVmdoyZvWFmX5rZcjO7y8yaR+WbmZmbWWG0PCHa/oyZrTezf5pZj10tG20fYmYfmtlaM/uDmb1mZhdWEXcmMf7IzBaZ2RozuyvpuU3N7L/NbLWZ/Qs4pZrP5zozm5iy7h4zuyN6fLGZLYjez7+iX/FV7WupmQ2IHueZ2Z+j2OYBR6V53Y+i/c4zszOj9d8G7gaOj6rmViV9tjckPf/S6L2vNrMnzGzfTD6bXfmcK+IxsxfM7AszW2FmP096nV9Gn8k6Mys1s/3SVdWZ2asV33P0ec6IXucL4DozO8jMpkfvZVX0ubVPen5B9B7Lou2/N7OWUcyHJpXb18w2mVmnqt6v1MDddWtAN2AxcHLKupuBrcAZhB8CrYCjgb6Es8X9gQ+B0VH5ZoADhdHyBGAVUAQ0B/4KTNiNsnsB64Gh0bb/ALYBF1bxXjKJ8UmgPVAIfFHx3oHRwDygK9AJmBH+3NO+zv7ABqB10r5XAkXR8hlRGQNOAjYDvaJtJwOLk/a1FBgQPb4deAnoCBQA81PKfg/YN/pOzo9i2DvadjHwUkqcE4AboseDoxiPAFoC/wO8mMlns4ufc3vgc+BKoAXQDiiOtv0CmAMcFL2HI4A9gQNTP2vg1YrvOXpv5cBlQFPC3+O3gEHAHtHfyWvA7Unv573o82wdlT8u2jYeGJf0Oj8FJsf9f1ifb7EHoFstf6FVJ4UXa3jefwL/Fz1Od6D/36SyZwLv7UbZkcArSdsMWE4VSSHDGPslbf8b8J/R4xmEarSKbaemHqhS9v0GcH70eAjwYTVl/w78JHpcXVJYkvxdAD9OLptmv+8Bp0WPa0oKDwO3JG1rR2hH6lrTZ7OLn/O/A6VVlPtXRbwp6zNJCh/VEMM5wMzo8fHACqBpmnLHAR8DFi3PBs6u7f+rxnRT9VHj8WnygpkdYmb/iKoD1gE3AvnVPH9F0uNNVN+4XFXZ/ZLj8PBfvLSqnWQYY0avBXxSTbwAfwGGR4/PBxKN82Z2upm9GVWffEn4lV7dZ1Vh3+piMLMLzWxOVAXyJXBIhvuF8P4S+3P3dcAaoEtSmYy+sxo+527Aoipi6EZIDLsj9e9xHzObZGafRTH8KSWGxR46NVTi7q8Rzjr6m1lPoDvwj92MSVCbQmOS2h3zPsIv0wPdvR3wK8Iv92xaTvglC4CZGZUPYqm+SYzLCQeTCjV1mf0rcLKZdSVUb/0lirEV8BjwX4SqnQ7AcxnGsaKqGMxsf+BeQhVKp2i/7yftt6bus8sIVVIV+2tLqKb6LIO4UlX3OX8KHFDF86ratjGKKS9p3T4pZVLf328Jvea+HcVwYUoMBWbWtIo4HgEuIJzVTHL3r6ooJxlQUmi82gJrgY1RQ92P6uA1/w70MbMzzKwZoZ66c5ZinARcZWZdokbHa6or7O6fE6o4/gh84O4Lo00tCPXcZcB2MzudUPedaQzXmlkHC9dxjE7a1oZwYCwj5MeLCWcKFT4HuiY3+KZ4FPihmfUysxaEpPWKu1d55lWN6j7np4DuZjbazPYws3ZmVhxtewC42cwOsOAIM9uTkAxXEDo0NDWzUSQlsGpi2AisNbNuhCqsCv8EVgO3WGi8b2VmxyVt/zOhuul8QoKQb0BJofH6KfADQsPvfYRfylkVHXjPBe4g/JMfALxD+IVY2zHeC0wD3gVmEn7t1+QvhDaCvyTF/CVwNTCZ0Fh7DiG5ZeJ6whnLYuAZkg5Y7j4XuAt4KypzCPBm0nOfBxYCn5tZcjVQxfOnEqp5JkfP7w6MyDCuVFV+zu6+FvgOMIzQsP0hcGK0+TbgCcLnvI7Q6Nsyqha8BLiW0OngwJT3ls71QDEhOT0FPJ4UQzlwOnAo4axhCeF7qNi+mPA9b3X313fxvUuKisYZkToXVQcsA85x91fijkfqLzN7hNB4fUPcsdR3unhN6pSZnUKoDthC6NJYTvi1LLJbovaZocC3446lIVD1kdS1/sBHhGqFU4DvqmFQdpeZ/RfhWolb3H1J3PE0BKo+EhGRBJ0piIhIQr1rU8jPz/fCwsK4wxARqVdmzZq1yt2r6wIO1MOkUFhYSGlpadxhiIjUK2ZW01X9gKqPREQkiZKCiIgkKCmIiEiCkoKIiCQoKYiISELWkoKZPWRmK83svSq2WzQd3yIzm2tmfbIVi4jkmJISKCyEJk3CfUlJTc+oG4orq2cKf6KaeXEJs1sdFN1GEUa1FKl/cvVAArkZW0kJjBoFn3wC7uF+1Kj4Y1NcQTandSPMDfteFdvuA4YnLX8A7FvTPo866igXyRkTJrjn5bmHf9dwy8sL6+OWq7EVFFSOqeJWUKC4shgXVUyrmnrL6thHZlYI/N3de6bZ9nfgN+7+arQ8DbjG3Xe6Mi2apGMUQPfu3Y/65JOMrsEQyb7CwvDLLVVBASxeXNfRVJarsTVpEg5rqczg66/rPp4KDTwuM5vl7kU1vtwuBVe70k1nmDZDuft4dy9y96LOnWu8Sluk7iypYmDOqtbXpVyNrXsVM6NWtb6uKC4g3qSwlMrz13YlTLgikl4u1o/n6oGkuhjijm3cOMjLq7wuLy+sj5PiCjKpY9rdG9W3KZxGmKLQgH7AW5nsU20KjVSu1o/nalz1IbaCAnezcJ8LMbk36LiIu03BzB4FBgD5hEnIrweaR4nof83MgLsJPZQ2ARd5mvaEVEVFRa4B8RqhXK0fh3DGMnZsqJbp3j38ghuxu9Ml17Jcjk3qVKZtCvVukh0lhUYqVxsBReqJ+tDQLJK5XK0fF2lglBSkfsjVRkCRBkZJQeqHESNg/PjQhmAW7sePV/24SC2rdzOvSSM2YoSSgEiW6UxBREQSlBRERCRBSUFERBKUFEREJEFJQUREEpQUREQkQUlBREQSlBRERCRBSUFERBKUFEREJEFJQUREEpQUREQkQUlBREQSlBRERCRBSUFERBKUFEREJEFJQUREEpQUREQkQUlBREQSlBRERCRBSUFERBKUFEREJEFJQUREErKaFMzsFDP7wMwWmdmYNNsLzGyamc01s5fMrGs24xERkeplLSmYWVPgHmAIcBgw3MwOSyl2O/CIu/cCbgT+K1vxiIhIzbJ5plAMLHL3j9x9KzARGJpS5jBgWvR4eprtIiJSh7KZFLoAnyYtL43WJZsDDIsenwW0NbNOqTsys1FmVmpmpWVlZVkJVkREspsULM06T1n+T+BEM3sHOBH4DCjf6Unu4929yN2LOnfuXPuRiogIAM2yuO+lQLek5a7AsuQC7r4MOBvAzNoAw9x9bRZjEhGRamTzTGEmcJCZ9TCzPYDzgKeSC5hZvplVxPAL4KEsxiMiIjXIWlJw93JgNPAssACY5O7zzOxGMzszKjYA+MDMPgT2BsZlKx7ZBSUlUFgITZqE+5KSuCMSkTpi7qnV/LmtqKjIS0tL4w6j4SopgVGjYNOmHevy8mD8eBgxIr64ROQbMbNZ7l5UUzld0SyVjR1bOSFAWB47Np54RKROKSlIZUuW7Np6EWlQlBSksu7dd229iDQoSgpS2bhxoQ0hWV5eWC8iDZ6SglQ2YkRoVC4oALNwr0ZmkUYjmxevSX01YoSSgEgjpTMFERFJUFIQEZEEJQUREUlQUhARkQQlBRERSVBSEBGRBCUFERFJUFIQEZEEJQUREUlQUhARkQQlBRERSVBSEBGRBCUFERFJUFIQEZEEJQUREUlQUhARkQQlBRERSVBSEBGRBCUFERFJUFIQEZEEJQUREUnIalIws1PM7AMzW2RmY9Js725m083sHTOba2anZjMeERGpXtaSgpk1Be4BhgCHAcPN7LCUYtcBk9z9SOA84H+yFY+IiNQsm2cKxcAid//I3bcCE4GhKWUcaBc9bg8sy2I8IiJSg2wmhS7Ap0nLS6N1yW4ALjCzpcDTwOXpdmRmo8ys1MxKy8rKshGriIiQ3aRgadZ5yvJw4E/u3hU4Ffizme0Uk7uPd/cidy/q3LlzFkIVERHIblJYCnRLWu7KztVDPwQmAbj7P4GWQH4WYxIRkWpkMynMBA4ysx5mtgehIfmplDJLgEEAZnYoISmofkhEJCZZSwruXg6MBp4FFhB6Gc0zsxvN7Myo2E+BS8xsDvAocKG7p1YxiYhIHWmWzZ27+9OEBuTkdb9KejwfOC6bMYiISOZ0RbOIiCTUmBTMbLSZdayLYEREJF6ZnCnsA8w0s0nRsBXpupqKiEgDUGNScPfrgIOAB4ELgYVmdouZHZDl2EREpI5l1KYQ9QhaEd3KgY7AY2Z2axZjExGROlZj7yMzuwL4AbAKeAD4mbtvi648Xgj8PLshiohIXcmkS2o+cLa7f5K80t2/NrPTsxOWiIjEIZPqo6eBLyoWzKytmfUFcPcF2QpMRETqXiZJ4V5gQ9LyxmidiIg0MJkkBUseesLdvybLV0KLiEg8MkkKH5nZFWbWPLpdCXyU7cBERKTuZZIULgWOBT4jDIfdFxiVzaBERCQeNVYDuftKwrDXIiLSwGVynUJLwmQ4hxPmOwDA3UdmMS4REYlBJtVHfyaMf/T/gJcJM6itz2ZQIiISj0ySwoHu/ktgo7s/DJwGfDu7YYmISBwySQrbovsvzawn0B4ozFpEIiISm0yuNxgfzadwHWGO5TbAL7MalYiIxKLapBANerfO3dcAM4D96yQqERGJRbXVR9HVy6PrKBYREYlZJm0Kz5vZf5pZNzPbs+KW9chERKTOZdKmUHE9wk+S1jmqShIRaXAyuaK5R10EIiIi8cvkiubvp1vv7o/UfjgiIhKnTKqPjk563BIYBLwNKCmIiDQwmVQfXZ68bGbtCUNfiIhIA5NJ76NUm4CDajsQERGJXyZtClMIvY0gJJHDgEmZ7NzMTgF+DzQFHnD336Rs/29gYLSYB+zl7h0yC11ERGpbJm0Ktyc9Lgc+cfelNT3JzJoC9wDfIUzOM9PMnnL3+RVl3P3qpPKXA0dmGriIiNS+TJLCEmC5u28BMLNWZlbo7otreF4xsMjdP4qeNxEYCsyvovxw4PqMohYRkazIpE3h/4Cvk5a3R+tq0gX4NGl5abRuJ2ZWAPQAXqxi+ygzKzWz0rKysgxeWkREdkcmSaGZu2+tWIge75HB8yzNOk+zDsJ0n4+5+/Z0G919vLsXuXtR586dM3hpERHZHZkkhTIzO7NiwcyGAqsyeN5SoFvScldgWRVlzwMezWCfIiKSRZm0KVwKlJjZ3dHyUiDtVc4pZgIHmVkP4DPCgf/81EJmdjDQEfhnRhGLiEjWZHLx2r+AfmbWBjB3z2h+ZncvN7PRwLOELqkPufs8M7sRKHX3p6Kiw4GJ7l5V1ZKIiNSRTK5TuAW41d2/jJY7Aj919+tqeq67Pw08nbLuVynLN+xKwCIikj2ZtCkMqUgIANEsbKdmLyQREYlLJkmhqZm1qFgws1ZAi2rKi4hIPZVJQ/MEYJqZ/TFavgh4OHshiYhIXDJpaL7VzOYCJxOuPZgKFGQ7MBERqXuZjpK6gnBV8zDCfAoLshaRiIjEpsozBTP7FuHaguHAauCvhC6pA6t6joiI1G/VVR+9D7wCnOHuiwDM7OpqyouISD1XXfXRMEK10XQzu9/MBpF+PCMREWkgqkwK7j7Z3c8FDgFeAq4G9jaze81scB3FJyIidajGhmZ33+juJe5+OmFQu9nAmKxHJiIidW6X5mh29y/c/T53PylbAYmISHx2KSmIiEjDpqQgIiIJSgoiIpKgpCAiIglKCiIikqCkICIiCUoKIiKSoKQgIiIJSgoiIpKgpBCnkhIoLIQmTcJ9SUncEYlII5fJdJySDSUlMGoUbNoUlj/5JCwDjBgRX1wi0qjpTCEuY8fuSAgVNm0K60VEYqKkEJclS3ZtvYhIHVBSiEv37ru2XkSkDigpxGXcOMjLq7wuLy+sFxGJiZJCXEaMgPHjoaAAzML9+PFqZBaRWGU1KZjZKWb2gZktMrO0s7WZ2ffMbL6ZzTOzv2QznpwzYgQsXgxffx3ulRBEJGZZ65JqZk2Be4DvAEuBmWb2lLvPTypzEPAL4Dh3X2Nme2UrHhERqVk2zxSKgUXu/pG7bwUmAkNTylwC3OPuawDcfWUW4xERkRpkMyl0AT5NWl4arUv2LeBbZvaamb1hZqek25GZjTKzUjMrLSsry1K4IiKSzaRgadZ5ynIz4CBgADAceMDMOuz0JPfx7l7k7kWdO3eu9UBFRCTIZlJYCnRLWu4KLEtT5kl33+buHwMfEJKEiIjEIJtJYSZwkJn1MLM9gPOAp1LKPAEMBDCzfEJ10kdZjElERKqRtaTg7uXAaOBZYAEwyd3nmdmNZnZmVOxZYLWZzQemAz9z99XZiklERKpn7qnV/LmtqKjIS0tL4w5DRKReMbNZ7l5UUzld0SwiIglKCiIikqBJdkSkcdq4EVauhLKyyverV8P27XFHl96wYXDssVl9CSUFEWkYNm/e+QBfcZ9u3ebN6ffTogU0b163sWfqsMOUFESkkfrqq6oP8unuN2xIv58WLWCvvaBz53B/6KGVl1PvW7eu2/eZY5QURKTurVkDL7wAn31W9UF+3br0z23evPJB/MADqz/It2kThqeXjCgpiEjd+PJLePJJmDQJnn8etm0L65s1q3wg79s33Fd1kG/XTgf5LFJSEJHsWbsWnnoqJIJnnw2JoKAArroqNJp+61vQoYMO8jlESUFEate6dTBlSkgEU6fC1q3QrRtccQV873tw9NFKAjlMSUFEvrn16+Hvfw+J4JlnQiNx167wk5+ERFBcDE10WVR9oKQgIrtnwwb4xz9CInj6adiyBfbbDy69NCSCfv2UCOohJQURydzGjSEBTJoUEsLmzbDPPnDJJSERHHusEkE9p6QQJ3e47Ta46aYdPTFySdOmkJ9fdS+Q1Pu8vLgjlmzYtClUCU2aFKqINm2CvfeGkSNDIjjuuPC3Ig2CkkJc3OFnP4Pf/Q6GDIFeveKOaGfbtoVL/iv6jc+bFx5v2ZK+fF5eZsmjorthq1Z1+34kc5s3h0biSZNCo/HGjeG7+8EPQiI4/nglggZKSSEO5eXhdPtPf4LRo+H3v68/p9zuVY8Zk3y/bBnMmROWt25Nv682bXYtibRoUbfvtbHZsiV0G500KXQj3bAhnClecEFIBCecEK4pkAZN33Bd27IFzjsvXMRzww3wq1/Vr+55ZuFg3qYN7L9/zeXdQ8+U1KSRmkg+/RRmzQrLVVWltWsXksR++8Exx8DAgaHqok2b2n2PjclXX8Fzz4VE8OST4bvq1AmGDw+JYMAAJYJGRpPs1KV162DoUHjpJbjrLrj88rgjyj3u4YKn6s5CPv4YSkvDGVezZqHf+4ABIUkce2yjH7umRl99Fa4orkgE69ZBx45w9tkhEQwcmLsDwsluy3SSHSWFurJyZWg7mDs3VBuNGBF3RPXbxo3w+uswfXpIsjNnhiTRvHnoE1+RJI45Rg3gEKrwXnghJIInngiJt0MHOOuskAgGDVIiaOCUFHLJJ5/A4MGhiuSxx+DUU+OOqOHZsAFee21HkigtDWPi77FHGEunIkn069c4GrhXrgwdA+bNC5/Fk0+GsYfat4fvfjckgpNPDp+PNApKCrliwYKQECqu+OzfP+6IGod16yoniVmz4OuvQ2N1v347kkTfvtCyZdzR7r5Vq3Yc/JNvq1btKLPnnnDaaSERfOc7arBvpJQUkpWUwNixsGQJdO8O48bVTfXNW2+Fs4JmzUJjXi52O20s1q6FV18NCWL6dHjnnR1J4thjdySJ4uLcPGh+8UX6g//KlTvKtGsHhx++823ffWulM8O2bdtYunQpW6rqkiw5oWXLlnTt2pXmKdWBSgoVSkpg1KhwwU2FvDwYPz67iWHatNCovNdeoVHvgAOy91qy6778El55ZUeSmD07NHK3bBmSxMCBIVEUF9dtFcuaNZUP+vPnh/sVK3aUads2zMCVevDv0iWrPdk+/vhj2rZtS6dOnbD61GOuEXF3Vq9ezfr16+nRo0elbUoKFQoLQ51+qoICWLy4tsKq7PHH4fzzw7DAzz4bulBKbluzBmbM2JEk5swJ61u1Ct1eK5LE0UfXToPs2rXpf/kvX76jTOvW6Q/+3brF0o15wYIFHHLIIUoIOc7def/99zn00EMrrc80KTT8DshLluza+m/q/vvDgGD9+oU2hI4ds/M6Urs6dgxndkOHhuXVqysnibFjw/rWrSsniaOOqj5JrFu349d+8u2zz3aUycsLB//Bg8NBvyIRdO+ecxc1KiHkvm/6HTX8pNC9e/ozhe7da/+1fvtbGDMGTjkl9DJSf/n6q1On0F3zrLPC8qpV8PLLIUm89BL84hdhfZs2ofPAwIEhQSxZUvng/+mnO/bZqlWYH/ikkyr/8i8oyLmDvzReDT8pjBuXvk1h3Ljaew13uOaaMLjd8OHhOgR19WtY8vPDTGHDhoXllSvDmURF76ZrrtlRtkWLcPA/4YTKB//CwsY1XlAtd/BYvXo1gwYNAmDFihU0bdqUzp07A/DWW2+xRwb/cxdddBFjxozh4IMPrrLMPffcQ4cOHRjRWK8lcvd6dTvqqKN8l02Y4F5Q4G4W7idM2PV9VGXbNveRI93B/cc/dt++vfb2LfXHihXuzz3n/uGH7uXlcUeTFfPnz8+88IQJ7nl54f+i4paXV2v/e9dff73fdtttO63/+uuvfbv+B9N+V0CpZ3CMzeo5q5mdYmYfmNkiMxuTZvuFZlZmZrOj28VZCWTEiNCo/PXX4b62fgFs2RL6fj/0UBjD6O67VQ3QWO29d7gG4KCDGtfZQFXGjq18dg5huaJtphYtWrSInj17cumll9KnTx+WL1/OqFGjKCoq4vDDD+fGG29MlO3fvz+zZ8+mvLycDh06MGbMGHr37s0xxxzDyqh773XXXcedd96ZKD9mzBiKi4s5+OCDef311wHYuHEjw4YNo3fv3gwfPpyioiJmz569U2zXX389Rx99dCI+jzr2fPjhh5x00kn07t2bPn36sDjq9HLLLbfw7W9/m969ezM2C59VJrJ2BDOzpsA9wBDgMGC4mR2Wpuhf3f2I6PZAtuKpdevWhWsQJk8Oo5z++tf1a2A7kWyq4w4e8+fP54c//CHvvPMOXbp04Te/+Q2lpaXMmTOH559/nvnz5+/0nLVr13LiiScyZ84cjjnmGB566KG0+3Z33nrrLW677bZEgvnDH/7APvvsw5w5cxgzZgzvvPNO2udeeeWVzJw5k3fffZe1a9cydepUAIYPH87VV1/NnDlzeP3119lrr72YMmUKzzzzDG+99RZz5szhpz/9aS19Orsmmz9ri4FF7v6Ru28FJgJDs/h6daesLDQWzpgBEyaECclFZIeqOnJko4MHcMABB3D00Ucnlh999FH69OlDnz59WLBgQdqk0KpVK4YMGQLAUUcdlfi1nurss8/eqcyrr77KeeedB0Dv3r05/PDD0z532rRpFBcX07t3b15++WXmzZvHmjVrWLVqFWeccQYQLjbLy8vjhRdeYOTIkbSKhmHZc889d/2DqAXZTApdgKSuFyyN1qUaZmZzzewxM+uWbkdmNsrMSs2stKysLBuxZm7JkjDByLx5YTyZxtoYJVKdceN2Hoiwtjt4JGmd1NNv4cKF/P73v+fFF19k7ty5nHLKKWmvwk5umG7atCnl5eVp990iusI9uUxFNVB1Nm3axOjRo5k8eTJz585l5MiRiTjSdRt195zo8pvNpJDu3aV+klOAQnfvBbwAPJxuR+4+3t2L3L2oordBLN5/P/RRX748DFtx2mnxxSKSy0aMCKMGFBSEatWCguyPIhBZt24dbdu2pV27dixfvpxnn3221l+jf//+TJo0CYB333037ZnI5s2badKkCfn5+axfv57HH38cgI4dO5Kfn8+UKVMA2LJlC5s2bWLw4ME8+OCDbN68GYAvvvii1uPORDa7pC4Fkn/5dwWWJRdw99VJi/cDv81iPN9MaWm4/qBZs9Bf/Ygj4o5IJLeNGBHLmXSfPn047LDD6NmzJ/vvvz/HHXdcrb/G5Zdfzve//3169epFnz596NmzJ+3bt69UplOnTvzgBz+gZ8+eFBQU0Ldv38S2kpISfvSjHzF27Fj22GMPHn/8cU4//XTmzJlDUVERzZs354wzzuCmm26q9dhrkrVhLsysGfAhMAj4DJgJnO/u85LK7Ovuy6PHZwHXuHu/6vYbyyipL74YrnTNzw/jGB14YN2+vkgOWLBgwU5DJzRW5eXllJeX07JlSxYuXMjgwYNZuHAhzXJklrp031Xsw1y4e7mZjQaeBZoCD7n7PDO7kdBf9ingCjM7EygHvgAuzFY8u+1vfwsXpGkcIxGJbNiwgUGDBlFeXo67c9999+VMQvimsvou3P1p4OmUdb9KevwL4BfZjOEbefDBcDV0375hHKOYegOISG7p0KEDs2bNijuMrNCVVlW57Ta4+OJwQdLzzyshiEijoKSQqmIco5//HM49F556SgPbiUij0TAqwWpLeXkY9vrBB+Gyy+APf9CQBSLxQZRfAAALqElEQVTSqOhMocKWLeHM4MEH4Ze/hHvuUUIQkUZHSQFg/fpwIdrf/gZ33gk33qhxjERyzIABA3a6EO3OO+/kxz/+cbXPa9OmDQDLli3jnHPOqXLfNXV1v/POO9mUNMjfqaeeypdffplJ6PWKksKqVWEco5dfhkcegSuvjDsiEUlj+PDhTJw4sdK6iRMnMnz48Iyev99++/HYY4/t9uunJoWnn36aDh067Pb+clXjblP49NMwBeLixWG002iAKhGpwVVXQZqhor+RI44IZ+pVOOecc7juuuv46quvaNGiBYsXL2bZsmX079+fDRs2MHToUNasWcO2bdu4+eabGTq08vibixcv5vTTT+e9995j8+bNXHTRRcyfP59DDz00MbQEwGWXXcbMmTPZvHkz55xzDr/+9a+56667WLZsGQMHDiQ/P5/p06dTWFhIaWkp+fn53HHHHYlRVi+++GKuuuoqFi9ezJAhQ+jfvz+vv/46Xbp04cknn0wMeFdhypQp3HzzzWzdupVOnTpRUlLC3nvvzYYNG7j88sspLS3FzLj++usZNmwYU6dO5dprr2X79u3k5+czbdq0WvwSGnNS+OCD0N107dpwUdoJJ8QdkYhUo1OnThQXFzN16lSGDh3KxIkTOffcczEzWrZsyeTJk2nXrh2rVq2iX79+nHnmmVUOMHfvvfeSl5fH3LlzmTt3Ln369ElsGzduHHvuuSfbt29n0KBBzJ07lyuuuII77riD6dOnk5+fX2lfs2bN4o9//CNvvvkm7k7fvn058cQT6dixIwsXLuTRRx/l/vvv53vf+x6PP/44F1xwQaXn9+/fnzfeeAMz44EHHuDWW2/ld7/7HTfddBPt27fn3XffBWDNmjWUlZVxySWXMGPGDHr06JGV8ZEaZ1KYNSuMY9SkicYxEtkd1fyiz6aKKqSKpFDx69zdufbaa5kxYwZNmjThs88+4/PPP2efffZJu58ZM2ZwRTTkfa9evejVq1di26RJkxg/fjzl5eUsX76c+fPnV9qe6tVXX+Wss85KjNR69tln88orr3DmmWfSo0cPjoiOL1UNz7106VLOPfdcli9fztatW+nRowcAL7zwQqXqso4dOzJlyhROOOGERJlsDK/d+NoUpk+HAQPCtQevvqqEIFKPfPe732XatGm8/fbbbN68OfELv6SkhLKyMmbNmsXs2bPZe++90w6XnSzdWcTHH3/M7bffzrRp05g7dy6nnXZajfupbvy4imG3oerhuS+//HJGjx7Nu+++y3333Zd4vXRDadfF8NqNKyk88UQ4QygogNdeC1Mniki90aZNGwYMGMDIkSMrNTCvXbuWvfbai+bNmzN9+nQ++eSTavdzwgknUFJSAsB7773H3LlzgTDsduvWrWnfvj2ff/45zzzzTOI5bdu2Zf369Wn39cQTT7Bp0yY2btzI5MmTOf744zN+T2vXrqVLlzDVzMMP75g9YPDgwdx9992J5TVr1nDMMcfw8ssv8/HHHwPZGV678SSFP/8Zhg2DPn3CjGld0s33IyK5bvjw4cyZMycx8xnAiBEjKC0tpaioiJKSEg455JBq93HZZZexYcMGevXqxa233kpxcTEQZlE78sgjOfzwwxk5cmSlYbdHjRrFkCFDGDhwYKV99enThwsvvJDi4mL69u3LxRdfzJFHHpnx+7nhhhv4t3/7N44//vhK7RXXXXcda9asoWfPnvTu3Zvp06fTuXNnxo8fz9lnn03v3r0599xzM36dTGVt6Oxs2e2hs197DW6/PUyfqWErRHaZhs6uP3Jy6Oycc9xx4SYiIlVqPNVHIiJSIyUFEclYfatuboy+6XekpCAiGWnZsiWrV69WYshh7s7q1atp2bLlbu+j8bQpiMg30rVrV5YuXUpZWVncoUg1WrZsSdeuXXf7+UoKIpKR5s2bJ66klYZL1UciIpKgpCAiIglKCiIiklDvrmg2szKg+oFNqpYPrKrFcGqL4to1imvX5WpsimvXfJO4Cty9c02F6l1S+CbMrDSTy7zrmuLaNYpr1+VqbIpr19RFXKo+EhGRBCUFERFJaGxJYXzcAVRBce0axbXrcjU2xbVrsh5Xo2pTEBGR6jW2MwUREamGkoKIiCQ0iqRgZg+Z2Uozey/uWJKZWTczm25mC8xsnpldGXdMAGbW0szeMrM5UVy/jjumZGbW1MzeMbO/xx1LBTNbbGbvmtlsM9uNqQGzw8w6mNljZvZ+9Hd2TA7EdHD0OVXc1pnZVXHHBWBmV0d/8++Z2aNmtvvDjdYiM7syimletj+rRtGmYGYnABuAR9y9Z9zxVDCzfYF93f1tM2sLzAK+6+7zY47LgNbuvsHMmgOvAle6+xtxxlXBzP4DKALaufvpcccDISkARe6eUxc8mdnDwCvu/oCZ7QHkufuXccdVwcyaAp8Bfd19dy9Kra1YuhD+1g9z981mNgl42t3/FHNcPYGJQDGwFZgKXObuC7Pxeo3iTMHdZwBfxB1HKndf7u5vR4/XAwuALvFGBR5siBabR7ec+PVgZl2B04AH4o4l15lZO+AE4EEAd9+aSwkhMgj4V9wJIUkzoJWZNQPygGUxxwNwKPCGu29y93LgZeCsbL1Yo0gK9YGZFQJHAm/GG0kQVdHMBlYCz7t7TsQF3An8HPg67kBSOPCcmc0ys1FxBxPZHygD/hhVtz1gZq3jDirFecCjcQcB4O6fAbcDS4DlwFp3fy7eqAB4DzjBzDqZWR5wKtAtWy+mpJADzKwN8DhwlbuvizseAHff7u5HAF2B4ugUNlZmdjqw0t1nxR1LGse5ex9gCPCTqMoybs2APsC97n4ksBEYE29IO0TVWWcC/xd3LABm1hEYCvQA9gNam9kF8UYF7r4A+C3wPKHqaA5Qnq3XU1KIWVRn/zhQ4u5/izueVFF1w0vAKTGHAnAccGZUfz8ROMnMJsQbUuDuy6L7lcBkQv1v3JYCS5PO8h4jJIlcMQR4290/jzuQyMnAx+5e5u7bgL8Bx8YcEwDu/qC793H3EwhV4VlpTwAlhVhFDboPAgvc/Y6446lgZp3NrEP0uBXhn+X9eKMCd/+Fu3d190JCtcOL7h77Lzkzax11FCCqnhlMOOWPlbuvAD41s4OjVYOAWDsxpBhOjlQdRZYA/cwsL/rfHERo54udme0V3XcHziaLn1ujmI7TzB4FBgD5ZrYUuN7dH4w3KiD88v134N2o/h7gWnd/OsaYAPYFHo56hjQBJrl7znT/zEF7A5PDcYRmwF/cfWq8ISVcDpREVTUfARfFHA8AUd34d4AfxR1LBXd/08weA94mVM+8Q+4Md/G4mXUCtgE/cfc12XqhRtElVUREMqPqIxERSVBSEBGRBCUFERFJUFIQEZEEJQUREUlQUhCJmNn2lNE7a+3qXzMrzLVRekXSaRTXKYhkaHM0tIdIo6UzBZEaRHMl/DaaY+ItMzswWl9gZtPMbG503z1av7eZTY7mo5hjZhVDJTQ1s/ujMfGfi64Wx8yuMLP50X4mxvQ2RQAlBZFkrVKqj85N2rbO3YuBuwkjtRI9fsTdewElwF3R+ruAl929N2GsoXnR+oOAe9z9cOBLYFi0fgxwZLSfS7P15kQyoSuaRSJmtsHd26RZvxg4yd0/igYwXOHuncxsFWGSpG3R+uXunm9mZUBXd/8qaR+FhCHID4qWrwGau/vNZjaVMAnUE8ATSXNZiNQ5nSmIZMareFxVmXS+Snq8nR1teqcB9wBHAbOiCV5EYqGkIJKZc5Pu/xk9fp0wWivACMJUjgDTgMsgMVlRu6p2amZNgG7uPp0weVAHYKezFZG6ol8kIju0ShqtFmCqu1d0S21hZm8SfkgNj9ZdATxkZj8jzHBWMQLplcB4M/sh4YzgMsJMXuk0BSaYWXvAgP/OwSkzpRFRm4JIDaI2hSJ3XxV3LCLZpuojERFJ0JmCiIgk6ExBREQSlBRERCRBSUFERBKUFEREJEFJQUREEv4/qsidfWI83x4AAAAASUVORK5CYII=\n"
                    },
                    "metadata": {
                        "needs_background": "light"
                    }
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### Use Word2Vec vectors as embedding layer for Deep Learning model"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Use our word2vec vocabulary as input to the embedding layer.\n\nfrom numpy import array\nfrom numpy import asarray\nfrom numpy import zeros\n\nwnl = WordNetLemmatizer()\nstop_words = set(stopwords.words('english'))\n\nfrom nltk.corpus import wordnet\n\ndef get_wordnet_pos(word):\n    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n    tag = nltk.pos_tag([word])[0][1][0].upper()\n    tag_dict = {\"J\": wordnet.ADJ,\n                \"N\": wordnet.NOUN,\n                \"V\": wordnet.VERB,\n                \"R\": wordnet.ADV}\n\n    return tag_dict.get(tag, wordnet.NOUN)\n\n# load doc into memory\ndef load_doc(filename):\n    # open the file as read only\n    file = open(filename, 'r')\n    # read all text\n    text = file.read()\n    # close the file\n    file.close()\n    return text\n\n# turn a doc into clean tokens\ndef clean_doc(doc, vocab):\n    # split into tokens by white space\n    tokens = doc.split()\n    # remove punctuation from each token\n    table = str.maketrans('', '', punctuation)\n    tokens = [w.translate(table) for w in tokens]\n    # remove remaining tokens that are not alphabetic\n    tokens = [word for word in tokens if word.isalpha()]\n    tokens = [wnl.lemmatize(w, get_wordnet_pos(w)) for w in tokens]\n    # filter out tokens not in vocab\n    tokens = [w for w in tokens if w in vocab]\n    \n    tokens = ' '.join(tokens)\n    return tokens\n\n# load all docs in a directory\ndef process_docs(x, vocab):\n    documents = list()\n    # walk through all files in the folder\n    #for filename in listdir(directory):\n    for doc in x:\n        # skip any reviews in the test set\n        #if is_trian and filename.startswith('cv9'):\n        #    continue\n        #if not is_train: # and not filename.startswith('cv9'):\n        #    continue\n        # create the full path of the file to open\n        #path = directory + '/' + filename\n        # load the doc\n        #doc = load_doc(path)\n        # clean doc\n        tokens = clean_doc(doc, vocab)\n        # add to list\n        documents.append(tokens)\n    return documents\n\n# load embedding as a dict\ndef load_embedding(filename):\n    # load embedding into memory, skip first line\n    file = open(filename,'r')\n    lines = file.readlines()[1:]\n    file.close()\n    # create a map of words to vectors\n    embedding = dict()\n    for line in lines:\n        parts = line.split()\n        # key is string word, value is numpy array for vector\n        embedding[parts[0]] = asarray(parts[1:], dtype='float32')\n    return embedding\n\n# create a weight matrix for the Embedding layer from a loaded embedding\ndef get_weight_matrix(embedding, vocab):\n    # total vocabulary size plus 0 for unknown words\n    vocab_size = len(vocab) + 1\n    # define weight matrix dimensions with all 0\n    weight_matrix = zeros((vocab_size, 100))\n    # step vocab, store vectors using the Tokenizer's integer mapping\n    for word, i in vocab.items():\n        weight_matrix[i] = embedding.get(word)\n    return weight_matrix\n\n# load the vocabulary\ndownload_file_cos(credentials_news,'vocab.txt','vocab.txt')\nvocab_filename = 'vocab.txt'\nvocab = load_doc(vocab_filename)\nvocab = vocab.split()\nvocab = set(vocab)\n\n# load all training reviews\n#positive_docs = process_docs('txt_sentoken/pos', vocab, True)\n#negative_docs = process_docs('txt_sentoken/neg', vocab, True)\n#train_docs = negative_docs + positive_docs\ntrain_docs = process_docs(Train_X, vocab)\n\n# create the tokenizer\ntokenizer = Tokenizer()\n# fit the tokenizer on the documents\ntokenizer.fit_on_texts(train_docs)\n\n# sequence encode\nencoded_docs = tokenizer.texts_to_sequences(train_docs)\n# pad sequences\nmax_length = max([len(s.split()) for s in train_docs])\nXtrain = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n# define training labels\nytrain = Train_Y # array([0 for _ in range(900)] + [1 for _ in range(900)])\n\n# load all test reviews\ntest_docs =   process_docs(Test_X, vocab)\n\n# sequence encode\nencoded_docs = tokenizer.texts_to_sequences(test_docs)\n# pad sequences\nXtest = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n# define test labels\nytest = Test_Y \n\n# define vocabulary size (largest integer value)\nvocab_size = len(tokenizer.word_index) + 1\n\n# load embedding from file\n\n#from gensim.models import Word2Vec\nembeddingword2vec_fn = \"embedding_word2vec.model\"\ndownload_file_cos(credentials_news, embeddingword2vec_fn, embeddingword2vec_fn)\nmodel = Word2Vec.load(embeddingword2vec_fn)\nmodel_vectors = model.wv\nwords = list(model.wv.vocab)\nprint('Vocabulary size: %d' % len(words))\n\n\nraw_embedding = load_embedding(embeddingword2vec_fn)\n# get vectors in the right order\nembedding_vectors = get_weight_matrix(raw_embedding, tokenizer.word_index)\n# create the embedding layer\nembedding_layer = Embedding(vocab_size, 100, weights=[embedding_vectors], input_length=max_length, trainable=False)\n\n# define model\nmodel = Sequential()\nmodel.add(embedding_layer)\nmodel.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\nmodel.add(MaxPooling1D(pool_size=2))\nmodel.add(Flatten())\nmodel.add(Dense(1, activation='sigmoid'))\nprint(model.summary())\n# compile network\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n# fit network\nhistory = model.fit(Xtrain, ytrain, epochs=9, validation_data=(Xtest, ytest))\n# evaluate\nloss, acc = model.evaluate(Xtest, ytest, verbose=0)\nprint('Test Accuracy: %f Loss: %f' % (acc*100, loss * 100 ))\n",
            "execution_count": null,
            "outputs": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.6",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.6.9",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}