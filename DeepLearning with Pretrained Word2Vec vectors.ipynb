{
    "cells": [
        {
            "metadata": {
                "collapsed": true
            },
            "cell_type": "markdown",
            "source": "### Deep learning with Pretrained Word2Vec Vectors \nWe will combine the 1D Convolutional model with Stanford's pre-trained GloVe vectors, which should have a much larger vocabulary and more accurate representations of word similarity than we have in our own small vocabulary.  \n"
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "!pip install --upgrade numpy\n!pip install --upgrade pandas\n#!pip install pyspark==2.4.5\n!pip install -U scikit-learn\n!pip install gensim",
            "execution_count": 1,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Collecting numpy\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/97/af8a92864a04bfa48f1b5c9b1f8bf2ccb2847f24530026f26dd223de4ca0/numpy-1.19.2-cp36-cp36m-manylinux2010_x86_64.whl (14.5MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14.5MB 7.9MB/s eta 0:00:01\n\u001b[31mERROR: tensorflow 1.13.1 requires tensorboard<1.14.0,>=1.13.0, which is not installed.\u001b[0m\n\u001b[31mERROR: autoai-libs 1.10.5 has requirement pandas>=0.24.2, but you'll have pandas 0.24.1 which is incompatible.\u001b[0m\n\u001b[?25hInstalling collected packages: numpy\n  Found existing installation: numpy 1.15.4\n    Uninstalling numpy-1.15.4:\n      Successfully uninstalled numpy-1.15.4\nSuccessfully installed numpy-1.19.2\nCollecting pandas\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/11/e1f53db0614f2721027aab297c8afd2eaf58d33d566441a97ea454541c5e/pandas-1.1.2-cp36-cp36m-manylinux1_x86_64.whl (10.5MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10.5MB 5.5MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pandas) (2.7.5)\nRequirement already satisfied, skipping upgrade: numpy>=1.15.4 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pandas) (1.19.2)\nRequirement already satisfied, skipping upgrade: pytz>=2017.2 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pandas) (2018.9)\nRequirement already satisfied, skipping upgrade: six>=1.5 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from python-dateutil>=2.7.3->pandas) (1.12.0)\n\u001b[31mERROR: ibm-watson-machine-learning 1.0.10 has requirement pandas<=0.25.3, but you'll have pandas 1.1.2 which is incompatible.\u001b[0m\nInstalling collected packages: pandas\n  Found existing installation: pandas 0.24.1\n    Uninstalling pandas-0.24.1:\n      Successfully uninstalled pandas-0.24.1\nSuccessfully installed pandas-1.1.2\nCollecting scikit-learn\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/a1/273def87037a7fb010512bbc5901c31cfddfca8080bc63b42b26e3cc55b3/scikit_learn-0.23.2-cp36-cp36m-manylinux1_x86_64.whl (6.8MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 6.8MB 5.6MB/s eta 0:00:01     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 6.8MB 5.6MB/s \n\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.13.3 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from scikit-learn) (1.19.2)\nRequirement already satisfied, skipping upgrade: scipy>=0.19.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from scikit-learn) (1.2.0)\nCollecting threadpoolctl>=2.0.0 (from scikit-learn)\n  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\nCollecting joblib>=0.11 (from scikit-learn)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/dd/0e015051b4a27ec5a58b02ab774059f3289a94b0906f880a3f9507e74f38/joblib-0.16.0-py3-none-any.whl (300kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 307kB 39.3MB/s eta 0:00:01\n\u001b[31mERROR: autoai-libs 1.10.5 has requirement scikit-learn==0.20.3, but you'll have scikit-learn 0.23.2 which is incompatible.\u001b[0m\n\u001b[?25hInstalling collected packages: threadpoolctl, joblib, scikit-learn\n  Found existing installation: scikit-learn 0.20.3\n    Uninstalling scikit-learn-0.20.3:\n      Successfully uninstalled scikit-learn-0.20.3\nSuccessfully installed joblib-0.16.0 scikit-learn-0.23.2 threadpoolctl-2.1.0\nCollecting gensim\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/e0/fa6326251692056dc880a64eb22117e03269906ba55a6864864d24ec8b4e/gensim-3.8.3-cp36-cp36m-manylinux1_x86_64.whl (24.2MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24.2MB 7.8MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: scipy>=0.18.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from gensim) (1.2.0)\nRequirement already satisfied: numpy>=1.11.3 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from gensim) (1.19.2)\nRequirement already satisfied: six>=1.5.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from gensim) (1.12.0)\nCollecting smart-open>=1.8.1 (from gensim)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/6f/788e657fb513deebadfbb38b346d4878b2fded0f72fe7d937b1646137f46/smart_open-2.1.1.tar.gz (111kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 112kB 28.2MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: requests in /opt/conda/envs/Python36/lib/python3.6/site-packages (from smart-open>=1.8.1->gensim) (2.21.0)\nRequirement already satisfied: boto in /opt/conda/envs/Python36/lib/python3.6/site-packages (from smart-open>=1.8.1->gensim) (2.49.0)\nRequirement already satisfied: boto3 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from smart-open>=1.8.1->gensim) (1.9.82)\nRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\nRequirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim) (2.8)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim) (2020.6.20)\nRequirement already satisfied: urllib3<1.25,>=1.21.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim) (1.24.1)\nRequirement already satisfied: botocore<1.13.0,>=1.12.82 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from boto3->smart-open>=1.8.1->gensim) (1.12.82)\nRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.9.3)\nRequirement already satisfied: s3transfer<0.2.0,>=0.1.10 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.1.13)\nRequirement already satisfied: docutils>=0.10 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.82->boto3->smart-open>=1.8.1->gensim) (0.14)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.82->boto3->smart-open>=1.8.1->gensim) (2.7.5)\nBuilding wheels for collected packages: smart-open\n  Building wheel for smart-open (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /home/dsxuser/.cache/pip/wheels/17/49/ea/74939572d8d071ff3c63a98e3e8dadef1117cc93c33efaa504\nSuccessfully built smart-open\nInstalling collected packages: smart-open, gensim\nSuccessfully installed gensim-3.8.3 smart-open-2.1.1\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "%matplotlib inline\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom pprint import pprint\nfrom time import time\nimport logging\nimport numpy as np\nimport pandas as pd\nimport string\nimport re\nfrom datetime import datetime\nfrom packaging import version\n\nfrom ibm_botocore.client import Config\nimport ibm_boto3\n\nfrom sklearn.model_selection import train_test_split\n#pd.show_versions()",
            "execution_count": 2,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#Get our data from IBM Cloud\n\n# @hidden_cell\n# The following code contains the credentials for a file in your IBM Cloud Object Storage.\n# You might want to remove those credentials before you share your notebook.\ncredentials_news = {\n    'IAM_SERVICE_ID': 'iam-ServiceId-32e8ee67-397c-4ff1-b69b-543172331f43',\n    'IBM_API_KEY_ID': 'Rx4FR4JSAueCnnIsoevsgYgOsuh8LCXtbkFpFpC0EmVU',\n    #'ENDPOINT': 'https://s3-api.us-geo.objectstorage.service.networklayer.com',\n    'ENDPOINT':'https://s3-api.us-geo.objectstorage.softlayer.net',\n    'IBM_AUTH_ENDPOINT': 'https://iam.cloud.ibm.com/oidc/token',\n    'BUCKET': 'advanceddatasciencecapstone-donotdelete-pr-tqabpnbxebk8rm',\n    'FILE': 'dfTrueFalseNews.pkl'\n}\n\ndef download_file_cos(credentials,local_file_name,key):  \n    cos = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id=credentials['IBM_API_KEY_ID'],\n    ibm_service_instance_id=credentials['IAM_SERVICE_ID'],\n    ibm_auth_endpoint=credentials['IBM_AUTH_ENDPOINT'],\n    config=Config(signature_version='oauth'),\n    endpoint_url=credentials['ENDPOINT'])\n    try:\n        res=cos.download_file(Bucket=credentials['BUCKET'],Key=key,Filename=local_file_name)\n    except Exception as e:\n        print(Exception, e)\n    else:\n        print('File Downloaded')\n\ndef upload_file_cos(credentials,local_file_name,key):  \n    cos = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id=credentials['IBM_API_KEY_ID'],\n    ibm_service_instance_id=credentials['IAM_SERVICE_ID'],\n    ibm_auth_endpoint=credentials['IBM_AUTH_ENDPOINT'],\n    config=Config(signature_version='oauth'),\n    endpoint_url=credentials['ENDPOINT'])\n    try:\n        res=cos.upload_file(Filename=local_file_name, Bucket=credentials['BUCKET'],Key=key)\n    except Exception as e:\n        print(Exception, e)\n    else:\n        print(' File Uploaded')\n        \ndfNews = download_file_cos(credentials_news, \"dfTrueFalseNews.pkl\", \"dfTrueFalseNews.pkl\")\ndfTrueFalseNews_tokenized  = download_file_cos(credentials_news,'dfTrueFalseNews_tokenized.pkl','dfTrueFalseNews_tokenized.pkl')",
            "execution_count": 3,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "File Downloaded\nFile Downloaded\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "dfNewsTemp = pd.read_pickle('dfTrueFalseNews.pkl')\ndfTrueFalseNews_tokenized = pd.read_pickle('dfTrueFalseNews_tokenized.pkl')\n#dfNews['truthvalue'] = pd.Categorical(dfNews['truthvalue'])\n\nx = dfNewsTemp['text'].values\n\ny = dfNewsTemp['truthvalue'].values\n\nprint (dfNewsTemp.shape, dfNewsTemp.columns, '\\n', dfNewsTemp.dtypes, type(x), type(y))\n",
            "execution_count": 8,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "(1126, 3) Index(['text', 'source', 'truthvalue'], dtype='object') \n text          object\nsource        object\ntruthvalue    object\ndtype: object <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### Download the pretrained vectors\nThis is the Stanford GloVe embedding\nWe download it and unzip it.  Then save the zipped file in case we need it tomorrow."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#!curl http://nlp.stanford.edu/data/glove.6B.zip --output glove.6B.zip -L\ndownload_file_cos(credentials_news, \"glove.6B.zip\", \"glove.6B.zip\")\n#!ls -al\n!unzip glove.6B.zip glove.6B.300d.txt\n#!ls -al\n#upload_file_cos(credentials_news, \"glove.6B.zip\", \"glove.6B.zip\")\n!rm glove.6B.zip\n!ls -al",
            "execution_count": 4,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "File Downloaded\nArchive:  glove.6B.zip\n  inflating: glove.6B.300d.txt       \ntotal 1020864\ndrwxr-x--- 2 dsxuser dsxuser       4096 Sep 19 19:27 .\ndrwx------ 1 dsxuser dsxuser       4096 Sep 19 19:24 ..\n-rw-r----- 1 dsxuser dsxuser    2228457 Sep 19 19:25 dfTrueFalseNews.pkl\n-rw-r----- 1 dsxuser dsxuser    5159678 Sep 19 19:25 dfTrueFalseNews_tokenized.pkl\n-rw-rw-r-- 1 dsxuser dsxuser 1037962819 Aug 27  2014 glove.6B.300d.txt\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### Prepare the Text for Word2Vec\n1. Change all the text to lower case\n2. Split stories into sentences.\n3. Word Tokenization and removing non-alpha text."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from nltk.tokenize import word_tokenize\nfrom nltk.tokenize import sent_tokenize\nfrom nltk import pos_tag\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.stem.porter import *\nfrom nltk.corpus import wordnet as wn\nfrom collections import defaultdict\nimport nltk\nnltk.download('punkt')\nnltk.download('wordnet')\nnltk.download('averaged_perceptron_tagger')\nnltk.download('stopwords')\n\n# reproduce the same result every time the script is run.\nnp.random.seed(500)",
            "execution_count": 5,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "[nltk_data] Downloading package punkt to /home/dsxuser/nltk_data...\n[nltk_data]   Unzipping tokenizers/punkt.zip.\n[nltk_data] Downloading package wordnet to /home/dsxuser/nltk_data...\n[nltk_data]   Unzipping corpora/wordnet.zip.\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /home/dsxuser/nltk_data...\n[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n[nltk_data] Downloading package stopwords to\n[nltk_data]     /home/dsxuser/nltk_data...\n[nltk_data]   Unzipping corpora/stopwords.zip.\n",
                    "name": "stderr"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from gensim.models import Word2Vec\nfrom string import punctuation\nfrom os import listdir\nfrom numpy import array\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.layers import Conv1D\nfrom tensorflow.keras.layers import MaxPooling1D\nfrom tensorflow.data import Dataset",
            "execution_count": 11,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "/opt/conda/envs/Python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n/opt/conda/envs/Python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n/opt/conda/envs/Python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n/opt/conda/envs/Python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n/opt/conda/envs/Python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n/opt/conda/envs/Python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
                    "name": "stderr"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### Use Stanford GloVe Word2Vec vectors as embedding layer for Deep Learning model"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Split into Train_X, Train_Y, Test_X, Test_Y\nfrom sklearn import model_selection\nTrain_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split(dfNewsTemp['text'],dfNewsTemp['truthvalue'],test_size=0.1)\ntrain_docs = tokenizer = test_docs = encoded_docs = None",
            "execution_count": 12,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "len(Train_X), len(Test_X), len(Train_Y), len(Test_Y)",
            "execution_count": 13,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 13,
                    "data": {
                        "text/plain": "(1013, 113, 1013, 113)"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Use the Stanford GloVe word2vec vocabulary as input to the embedding layer.\n\nfrom gensim.models import Word2Vec\nfrom numpy import array\nfrom numpy import asarray\nfrom numpy import zeros\n\nwnl = WordNetLemmatizer()\nstop_words = set(stopwords.words('english'))\n\nfrom nltk.corpus import wordnet\n\n\n# load doc into memory\ndef load_doc(filename):\n    # open the file as read only\n    file = open(filename, 'r')\n    # read all text\n    text = file.read()\n    # close the file\n    file.close()\n    return text\n\n# turn a doc into clean tokens\ndef clean_doc(doc, vocab):\n    # split into tokens by white space\n    tokens = doc.split()\n    # remove punctuation from each token\n    table = str.maketrans('', '', punctuation)\n    tokens = [w.translate(table) for w in tokens]\n    # remove remaining tokens that are not alphabetic\n    tokens = [word for word in tokens if word.isalpha()]\n    #tokens = [wnl.lemmatize(w, get_wordnet_pos(w)) for w in tokens] # the prepared embedding has all forms of verbs, so this isn't neccesary.\n    \n    # filter out tokens not in vocab\n    tokens = [w for w in tokens if w in vocab]\n    \n    tokens = ' '.join(tokens)\n    return tokens\n\n# load all docs in a directory\ndef process_docs(x, vocab):\n    documents = list()\n    # walk through all files in the folder\n    #for filename in listdir(directory):\n    for doc in x:\n        # skip any reviews in the test set\n        #if is_trian and filename.startswith('cv9'):\n        #    continue\n        #if not is_train: # and not filename.startswith('cv9'):\n        #    continue\n        # create the full path of the file to open\n        #path = directory + '/' + filename\n        # load the doc\n        #doc = load_doc(path)\n        # clean doc\n        tokens = clean_doc(doc, vocab)\n        # add to list\n        documents.append(tokens)\n    return documents\n\n# load embedding as a dict\ndef load_embedding(filename):\n    # load embedding into memory, skip first line\n    file = open(filename,'r')\n    lines = file.readlines()[1:]\n    file.close()\n    # create a map of words to vectors\n    embedding = dict()\n    for line in lines:\n        parts = line.split()\n        # key is string word, value is numpy array for vector\n        embedding[parts[0]] = asarray(parts[1:], dtype='float32')\n    return embedding\n\n# create a weight matrix for the Embedding layer from a loaded embedding\ndef get_weight_matrix(embedding, vocab):\n    # total vocabulary size plus 0 for unknown words\n    vocab_size = len(vocab) + 1\n    # define weight matrix dimensions with all 0\n    weight_matrix = zeros((vocab_size, 100))\n    # step vocab, store vectors using the Tokenizer's integer mapping\n    for word, i in vocab.items():\n        weight_matrix[i] = embedding.get(word)\n    return weight_matrix\n\n# load the vocabulary\ndownload_file_cos(credentials_news,'vocab.txt','vocab.txt')\nvocab_filename = 'vocab.txt'\nvocab = load_doc(vocab_filename)\nvocab = vocab.split()\nvocab = set(vocab)\n\n# load all training stories\nprint (\"processing training docs\")\ntrain_docs = process_docs(Train_X, vocab)\n\n\n# create the tokenizer\ntokenizer = Tokenizer()\n# fit the tokenizer on the documents\ntokenizer.fit_on_texts(train_docs)\n\n# sequence encode\nencoded_docs = tokenizer.texts_to_sequences(train_docs)\n# pad sequences\nmax_length = max([len(s.split()) for s in train_docs])\nprint (\"Found max_length \", max_length)\nXtrain = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n# define training labels\nytrain = Train_Y # array([0 for _ in range(900)] + [1 for _ in range(900)])\n\n# load all test reviews\ntest_docs = process_docs(Test_X, vocab)\n\n# sequence encode\nencoded_docs = tokenizer.texts_to_sequences(test_docs)\n# pad sequences\nXtest = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n# define test labels\nytest = Test_Y \n\n# define vocabulary size (largest integer value)\nvocab_size = len(tokenizer.word_index) + 1\n\n# load embedding from file\n\n#load GloVe embedding\nembeddingword2vec_fn = 'glove.6B.100d.txt'\ndownload_file_cos(credentials_news, embeddingword2vec_fn, embeddingword2vec_fn)\nraw_embedding = load_embedding(embeddingword2vec_fn)\n# get vectors in the right order\nembedding_vectors = get_weight_matrix(raw_embedding, tokenizer.word_index)\n# create the embedding layer\nembedding_layer = Embedding(vocab_size, 100, weights=[embedding_vectors], input_length=max_length, trainable=False)\n\n# define model\nmodel = Sequential()\nmodel.add(embedding_layer)\nmodel.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\nmodel.add(MaxPooling1D(pool_size=2))\nmodel.add(Flatten())\nmodel.add(Dense(1, activation='sigmoid'))\nprint(model.summary())\n# compile network\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n# fit network\nprint (len(Xtrain), len(ytrain), len(Xtest), len(ytest))\nhistory = model.fit(Xtrain, ytrain, epochs=6, validation_data=(Xtest, ytest))\n# evaluate\nloss, acc = model.evaluate(Xtest, ytest, verbose=0)\nprint('Test Accuracy: %f Loss: %f' % (acc*100, loss * 100 ))\n",
            "execution_count": 21,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "File Downloaded\nprocessing training docs\n<class 'Exception'> An error occurred (404) when calling the HeadObject operation: Not Found\nWARNING:tensorflow:From /opt/conda/envs/Python36/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (None, 6347, 100)         752000    \n_________________________________________________________________\nconv1d (Conv1D)              (None, 6343, 128)         64128     \n_________________________________________________________________\nmax_pooling1d (MaxPooling1D) (None, 3171, 128)         0         \n_________________________________________________________________\nflatten (Flatten)            (None, 405888)            0         \n_________________________________________________________________\ndense (Dense)                (None, 1)                 405889    \n=================================================================\nTotal params: 1,222,017\nTrainable params: 470,017\nNon-trainable params: 752,000\n_________________________________________________________________\nNone\n1013 1013 113 113\nTrain on 1013 samples, validate on 113 samples\nWARNING:tensorflow:From /opt/conda/envs/Python36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\nEpoch 1/6\n1013/1013 [==============================] - 108s 107ms/sample - loss: 7.9607 - acc: 0.4886 - val_loss: 7.6185 - val_acc: 0.5221\nEpoch 2/6\n1013/1013 [==============================] - 94s 93ms/sample - loss: 8.1364 - acc: 0.4896 - val_loss: 7.6185 - val_acc: 0.5221\nEpoch 3/6\n1013/1013 [==============================] - 93s 92ms/sample - loss: 8.1364 - acc: 0.4896 - val_loss: 7.6185 - val_acc: 0.5221\nEpoch 4/6\n1013/1013 [==============================] - 96s 95ms/sample - loss: 8.1364 - acc: 0.4896 - val_loss: 7.6185 - val_acc: 0.5221\nEpoch 5/6\n1013/1013 [==============================] - 110s 108ms/sample - loss: 8.1364 - acc: 0.4896 - val_loss: 7.6185 - val_acc: 0.5221\nEpoch 6/6\n1013/1013 [==============================] - 108s 107ms/sample - loss: 8.1364 - acc: 0.4896 - val_loss: 7.6185 - val_acc: 0.5221\nTest Accuracy: 52.212387 Loss: 761.848474\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from gensim.models import Word2Vec\nfrom numpy import array\nfrom numpy import asarray\nfrom numpy import zeros\n\n# load embedding as a dict\ndef load_embedding(filename):\n    # load embedding into memory, skip first line\n    file = open(filename,'r')\n    lines = file.readlines()[1:]\n    file.close()\n    # create a map of words to vectors\n    embedding = dict()\n    for line in lines:\n        parts = line.split()\n        # key is string word, value is numpy array for vector\n        embedding[parts[0]] = asarray(parts[1:], dtype='float32')\n    return embedding\n\n\ndef get_weight_matrix(embedding, vocab):\n    # total vocabulary size plus 0 for unknown words\n    vocab_size = len(vocab) + 1\n    # define weight matrix dimensions with all 0\n    weight_matrix = zeros((vocab_size, 100))\n    # step vocab, store vectors using the Tokenizer's integer mapping\n    for word, i in vocab.items():\n        weight_matrix[i] = embedding.get(word)\n    return weight_matrix\n\n#load GloVe embedding\nembeddingword2vec_fn = 'glove.6B.300d.txt'\n#download_file_cos(credentials_news, embeddingword2vec_fn, embeddingword2vec_fn)\nraw_embedding = load_embedding(embeddingword2vec_fn)\n# get vectors in the right order\nembedding_vectors = get_weight_matrix(raw_embedding, tokenizer.word_index)\n# create the embedding layer\nembedding_layer = Embedding(vocab_size, 100, weights=[embedding_vectors], input_length=max_length, trainable=False)\n\n# create a weight matrix for the Embedding layer from a loaded embedding\n",
            "execution_count": 15,
            "outputs": [
                {
                    "output_type": "error",
                    "ename": "AttributeError",
                    "evalue": "'NoneType' object has no attribute 'word_index'",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
                        "\u001b[0;32m<ipython-input-15-98315594c0e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mraw_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddingword2vec_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# get vectors in the right order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0membedding_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_weight_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;31m# create the embedding layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0membedding_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0membedding_vectors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'word_index'"
                    ]
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def clean_doc(doc, vocab):\n    # split into tokens by white space\n    tokens = doc.split()\n    # remove punctuation from each token\n    table = str.maketrans('', '', punctuation)\n    tokens = [w.translate(table) for w in tokens]\n    # remove remaining tokens that are not alphabetic\n    tokens = [word for word in tokens if word.isalpha()]\n    #tokens = [wnl.lemmatize(w, get_wordnet_pos(w)) for w in tokens] # the prepared embedding has all forms of verbs, so this isn't neccesary.\n    \n    # filter out tokens not in vocab\n    tokens = [w for w in tokens if w in vocab]\n    \n    tokens = ' '.join(tokens)\n    return tokens\n\nclean_doc(Train_X[0])",
            "execution_count": 27,
            "outputs": [
                {
                    "output_type": "error",
                    "ename": "TypeError",
                    "evalue": "clean_doc() missing 1 required positional argument: 'vocab'",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
                        "\u001b[0;32m<ipython-input-27-5ed5faef3389>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mclean_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrain_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
                        "\u001b[0;31mTypeError\u001b[0m: clean_doc() missing 1 required positional argument: 'vocab'"
                    ]
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# create the tokenizer\ntokenizer = Tokenizer()\n# fit the tokenizer on the documents\ntokenizer.fit_on_texts(train_docs)\n\n# sequence encode\nencoded_docs = tokenizer.texts_to_sequences(train_docs)\n# pad sequences\nmax_length = max([len(s.split()) for s in train_docs])\nXtrain = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n# define training labels\nytrain = Train_Y # array([0 for _ in range(900)] + [1 for _ in range(900)])\n\n# load all test reviews\ntest_docs = process_docs(Test_X, vocab)\n\n# sequence encode\nencoded_docs = tokenizer.texts_to_sequences(test_docs)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "history_dict = history.history\nhistory_dict.keys()\n\nacc = history_dict['acc']\nval_acc = history_dict['val_acc']\nloss = history_dict['loss']\nval_loss = history_dict['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\n# \"bo\" is for \"blue dot\"\nplt.plot(epochs, loss, 'bo', label='Training loss')\n# b is for \"solid blue line\"\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()",
            "execution_count": 61,
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": "<Figure size 432x288 with 1 Axes>",
                        "image/png": "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\n"
                    },
                    "metadata": {
                        "needs_background": "light"
                    }
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "plt.clf()   # clear figure\n\nplt.plot(epochs, acc, 'ro', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.show()",
            "execution_count": 62,
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": "<Figure size 432x288 with 1 Axes>",
                        "image/png": "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\n"
                    },
                    "metadata": {
                        "needs_background": "light"
                    }
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.6",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.6.9",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}